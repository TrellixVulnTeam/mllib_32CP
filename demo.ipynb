{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install \n",
    "!pip install -e https://github.com/eltoto1219/vltk.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vltk.abc.extraction import VizExtractionAdapter, VizExtractionAdapters\n",
    "from vltk.abc.visnadapter import VisnDatasetAdatpter, VisnDatasetAdapters\n",
    "from vltk.abc.visnlangadatper import VisnLangDatasetAdapter, VisnLangDatasetAdapters\n",
    "import vltk\n",
    "from vltk.modeling.frcnn import FRCNN as FasterFRCNN\n",
    "from vltk.configs import ProcessorConfig\n",
    "from vtk import compat\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTDIR = \"/home/eltoto/vltk/tests\"\n",
    "DATADIR = \"/home/eltoto/data\"\n",
    "COCODIR = \"/home/eltoto/vltk/tests/coco\"\n",
    "VGDIR =   \"/home/eltoto/vltk/tests/visualgenome\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define visual feature extraction adapter for FRCNN\n",
    "class FRCNN(VizExtractionAdapter):\n",
    "\n",
    "        default_processor = ProcessorConfig(\n",
    "        **{\n",
    "            \"transforms\": [\"ToPILImage\", \"ToTensor\", \"ResizeTensor\", \"Normalize\"],\n",
    "            \"size\": (800, 1333),\n",
    "            \"mode\": \"bilinear\",\n",
    "            \"pad_value\": 0.0,\n",
    "            \"mean\": [102.9801, 115.9465, 122.7717],\n",
    "            \"sdev\": [1.0, 1.0, 1.0]\n",
    "        }\n",
    "    )\n",
    "    model_config = compat.Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
    "    weights = \"unc-nlp/frcnn-vg-finetuned\"\n",
    "    model = FasterRCNN\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vision dataset adatpers for COCO + visualo genome\n",
    "class Coco2014(VisnDatasetAdapter):\n",
    "    def schema():\n",
    "        return {\n",
    "          vltk.box: Features.box\n",
    "          vltk.segmentation: Features.segmentation\n",
    "        }\n",
    "    ...\n",
    "    \n",
    "class VisualGenome(VisnDatasetAdapter):\n",
    "    def schema():\n",
    "        return {\n",
    "          vltk.box: Features.box\n",
    "          vltk.segmentation: Features.segmentation\n",
    "        }\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vision-language dataset adapters for VQA + GQA\n",
    " 7 class GQA(VisnLangDatasetAdapter):\n",
    "  6     name = \"gqa\"\n",
    "  5     data_info = {\n",
    "  4     ¦   \"dev\": {\"coco2014\": [\"test\"]},\n",
    "  3     ¦   \"train\": {\"vg\": [\"train\"]},\n",
    "  2     ¦   \"val\": {\"vg\": [\"train\"]},\n",
    "  1     ¦   \"test\": {\"coco2014\": [\"test\"]},\n",
    "17      }\n",
    "  1     default_features = {\n",
    "  2     ¦   \"qid\": ds.Value(\"string\"),\n",
    "  3     ¦   \"structure\": ds.Value(\"string\"),\n",
    "  4     ¦   \"super_class\": ds.Value(\"string\"),\n",
    "  5     ¦   \"operations\": ds.Sequence(length=-1, feature=ds.Value(\"string\")),\n",
    "  6     }\n",
    "class VQA(VisnLangDatasetAdapter):\n",
    " 14     name = \"vqa\"\n",
    " 15     data_info = {\n",
    " 16     ¦   \"val\": {\"coco2014\": [\"val\"]},\n",
    " 17     ¦   \"train\": {\"coco2014\": [\"train\"]},\n",
    " 18     ¦   \"test\": {\"coco2014\": [\"test\"]},\n",
    " 19     }\n",
    " 20     default_features = {\n",
    " 21     ¦   \"qid\": ds.Value(\"string\"),\n",
    " 22     }\n",
    " 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add adapters to library\n",
    "VisnLangDatasetAdapters.add(\"vqa\", VQA)\n",
    "VisnLangDatasetAdapters.add(\"gqa\", GQA)\n",
    "VisnDatasetAdapters.add(\"coco2014\", Coco2014)\n",
    "VisnDatasetAdapters.add(\"visualgenome\", VisualGenome)\n",
    "VizExtractionAdapters.add(\"frcnn\", FRCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# superset datasets together\n",
    "\n",
    "from vltk import DataConfigimport vltk\n",
    "#define config for datasetconfig = DataConfig(\n",
    "# choose which dataset and dataset split for train and eval\n",
    "train_datasets=[[\"gqa’, ’train’], [’vqa’,’trainval’]],\n",
    "eval_datasetts=[’gqa’, ’testdev’],\n",
    "# choose which tokenizer to use\n",
    "tokenizer=’BertWordPeice’,# choose which feature extractor to use\n",
    "extractor=’frcnn’)\n",
    "# use config to create dataset\n",
    "dataset = vltk.init_dataset(config)\n",
    "# first entry in the dataset\n",
    "dataset[0]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vltk import VLDataset\n",
    "# iterate through dataset\n",
    "for batch in dataset:\n",
    "    print(batch)\n",
    "    VLDataset.transpose(batch)\n",
    "    print(batch)\n",
    "    break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
