models:
  models_to_devices: [[lxmert, 1], [deit, 0]]

  lxmert:
    checkpoint: "unc-nlp/lxmert-base-uncased"
    visual_feat_dim: 576
    topk_patches: 100
  deit:
    checkpoint: '/playpen1/home/avmendoz/data/deit/pytorch_model.bin'
    distillation_type: "soft"
    embed_dim: 576
    patch_size: 28
    img_size: 576
    mlp_ratio: 4.0
    num_heads: 12
    freeze_layers: [1,1,1,1,1,1,1,1,1,1,1,1]
    qkv_bias: true

data:
  num_workers: 4
  eval_datasets:
    [[gqa, [dev]]]
  train_datasets:
    [[gqa, [val]], [gqa, [train]]]

  skip_eval: false
  img_first: true
  overwrite_cache_batch: true
  extractor: null
  min_size: 576
  max_size: 576
  train_batch_size: 4
  eval_batch_size: 1
test_run: false
break_loop_on_test: false
email: avmendoz@cs.unc.edu
save_on_crash: true
email_on_failure: true
save_after_epoch: true
